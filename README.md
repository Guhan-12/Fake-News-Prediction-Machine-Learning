# FakeNewsPredictionProject
I worked with a dataset of around 6500+ news articles to build a model that accurately classifies news as fake or real.

**Key Highlights of the Project**:
1. **Data Preprocessing**: Collected and cleaned a large dataset, applied text preprocessing techniques including tokenization and stemming, and utilized TF-IDF vectorizer for feature extraction.
2. **Model Development**: Trained a logistic regression model, achieving a training accuracy of 97.6% and a testing accuracy of 95.4%.
3. **Model Evaluation**: Evaluated model performance using metrics such as accuracy, precision analysis.

The technologies and tools I used for this project includes:
1. **Development Environment**: Google Colab
2. **Programming Languages**: Python
3. **Libraries and Frameworks**: pandas, numpy, scikit-learn
4. **Natural Language Processing**: Tokenization, Stemming, TF-IDF Vectorizer
5. **Machine Learning Model**: Logistic Regression model

The reason to use Logistic Regression model is that it inherently designed for binary classification problems, making it an ideal choice for distinguishing between fake and real news. It provides clear insights into the relationship between features and the target variable, allowing us to understand which words or phrases are strong indicators of fake or real news.
